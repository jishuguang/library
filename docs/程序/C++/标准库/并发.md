# 并发

## 概述

Approches to concurrency:
- multiple processes
- multiple threads

Why use concurrency:
- for separation of concerns
- for performance: task and data parallelism

## 线程管理

Basic thread managment
- Launch: `std::thread` constructor
- Wait or not：`join` or `detach`

Passing args
- copy
- std::move
- std::ref
- object pointer for member function

Thread ownership
- movable
- `std::jthread`

Thread amount
- `std::thread::hardware_concurrency()`

Identifying thread
- `std::thread::get_id()`
- `std::this_thread::get_id()`

## 线程共享数据

Problem
- race condition
- broken invariant

Avoid race condition
- wrap structure under protection guard
- refine structure using lock-free programming
- software transactional memory (STM)

### Mutex

Using mutex
- `std::mutex`
- `std::lock_guard`
    - `std::adopt_lock`

Avoid deadlock
- avoid nested lock
- avoid calling user-supplied code while holding a lock
- acquire lock in a fixed order
    - `std::lock`
    - `std::scoped_lock`
    - hand-over-hand locking
    - use a lock hierachy

`std::unique_lock`
- slight larger and slower than `std::lock_guard`
- use case
    - `std::defer_lock`
    - transfer ownership (moveable / not copyable)
    - flexible locking: doesn’t always own the mutex

Attention
- Don’t pass pointers and references to protected data outside the scope of the lock
- lock granularity
    - minimum necessary data
    - minimum possible time

### Alternative facilities

Protecting data during initialization
- problem: infamous double-checked locking
- `std::call_once, std::once_flag`
- static local variable

Protecting rarely updated data
- `std::shared_mutex`
    - exclusive locking: `std::lock_guard, std::unique_lock`
    - shared locking: `std::shared_lock`

Recursive locking (lead to sloppy thinking and
bad design)
- `std::recursive_mutex`

## 线程同步

### Waiting for an event with condition

condition variable
- `std::condition_variable`
- `std::condition_variable_any`
- need the `std::unique_lock` to lock/unlock internally

spurious wake
- code must be prepared
- minimal implementation: busy waiting

thread-safe queue with condition variable

### Waiting for one-off events

future
- `std::future` (only movable)
    - to share: `share` or `std::move`
- `std::shared_future`
    - need a copy of the shared_future object to each thread
- future objects themselves don’t provide synchronized accesses

return value from background task
- `std::async` retrun `std::future` holding the result
    - wait
    - get
- `std::launch::deferred, std::launch::async`

associating a task with a future
- `std::packaged_task` (callable object)
- `get_future` return `std::future`

making promise
- `std::promise<T>`
- `set_value`
- `get_future` return `std::future<T>` 

saving exception
- exception is stored in the future
- `some_promise.set_exception`

### Wait with a time limit

Clocks
- basic info
    - now
    - the type of the value
    - tick period: `std::ratio<60, 1>`
    - steady or not
- clock
    - system clock
    - steady clock
    - high resolution clock

Durations
- `std::chrono::duration<type, tick period>`
    - typedefs: nanoseconds, seconds, minutes, hours
- `std::chrono_literals`
- duration cast
    - implicit: do not require trunction
    - explicit: `std::duration_cast<>`
- `count`

Time points
- `std::chrono::time_point<clock, duration>`: time since epoch
- calculation
    - time_point with duration
    - time_point with time_point

Functions with timeout
- `std::this_thread::sleep_for/until`
- `std::timed_mutex.try_lock_for/until`
- ......

### Using synchronization to simplify code

Functional programming using future
- FP: the result of a function call depends solely on the parameters
- FP-Style parallel quicksort

Synchronizing operations with message passing
- CSP (Communicating Sequential Processes)
- Actor model

Continuation style
- feture.then(continuation)
- chain continuation
    - exception
    - future unwarpping

Waiting all or any
- when_all(begin, end)
- when_any(begin, end)

latches and barriers
- latch
    - count_down
    - wait
- barrier (reusable)
    - arrive_and_wait
- flex_barrier

## The C++ memory model and atomic operations

### Memory model

Objects and memory location
- object: a region of storage
- a object is stored in one or more memory locations
    - Every variable is an object, including those that are members of other objects.
    - Every object occupies at least one memory location.
    - Variables of fundamental types such as int or char occupy exactly one memory location, whatever their size, even if they’re adjacent or part of an array.
    - Adjacent bit fields are part of the same memory location.

Memory location and concurrency
- everything hinges on those memory locations. 
- if one or both of those accesses is not atomic, and if one or both is a write, then this is a data race.
- In order to avoid the race condition, there has to be an enforced ordering.

Modification order
- a modification order composed of all the writes to that object from all threads in the program.
- all threads in the system must agree on the order.
- don’t necessarily have to agree on the relative order of operations on separate objects.

### Atomic operations and types

atomic operations
- An atomic operation is an indivisible operation.
- `is_lock_free, is_always_lock_free`

`atomic_flag`
- `ATOMIC_FLAG_INIT` (initialization)
- `clear`
- `test_and_set`

`atomic<bool>`
- `store`
- `load`
- `exchange` (read-modify-write)
- `compare_exchange_weak/strong` (read-modify-write)
    - spurious failure: e.g. for machines that lack a single compare-and-exchange instruction

`atomic<T*>`
- `fetch_add/+=, fetch_sub/-=`
- `++, --`

atomic integral types
- `fetch_and, fetch_or, fetch_xor`

primary class template
- criteria: trivial copy-assignment operator, ...
- there are no atomic arithmetic operations on floating-point values

free functions for atomic operations
- `atomic_load, atomic_load_explict`

### Synchronizing operations and enforcing ordering

relationship
- synchronizes-with
- happens-before
    - strongly-happens-before (no memory_order_consume participation)

memory order
- `memory_order_seq_cst` (sequentially consistent ordering)
    - all threads must see the same order of operations
    - This constraint doesn’t carry forward to threads that use atomic operations with relaxed memory orderings
- `consume, acquire, release, acq_rel` (acquire-release ordering)
    - A release operation synchronizes-with an acquire operation that reads the value written
    - transitive
    - mix seq_cst & acq_rel: seq_cst behave like load_acq, store_rel, RMW_acq_rel
    - consume: dependency-ordered-before
- `relaxed` (relaxed ordering)
    - the only requirement is that all threads agree on the modification order of each individual variable

release sequence and synchronize-with
- the RMW chain of operations constitutes a release sequence and the initial store_rel synchronizes with the final load_acq.
- Any atomic read-modify-write operations in the chain can have any memory ordering.

fence
- `std::atomic_thread_fence` global operations
- if an acquire operation sees the result of a store that takes place after a release fence, the fence synchronizes with that acquire operation
- if a load that takes place before an acquire fence sees the result of a release operation, the release operation synchronizes with the acquire fence. 
- You can have fences on both sides.

ordering non-atomic operations
- sequence before
- high level mechanism provides ordering guarantees in terms of the synchronizes-with relationship

## lock-based concurrent data structure

### Guidelines for designing data structures for concurrency

guidelines
- thread safe
    - see broken invariants exclusively
    - avoid race conditions inherent in the interface
    - exception safe
    - restrict locks to avoid deadlock
- opportunity for concurrency (against serialization)
    - restrict the scope of locks
    - different locks for diffferent parts

### lock-based concurrent structures

thread-safe stack
- wrapper of std::stack

thread-safe queue
- wrapper of std::queue
- fine-grained locks for head and tail using a single-linked list

thread-safe map
- wrapper of std::map
- hash map using std::list bucket with shared_lock and unique_lock for each bucket
- fine-grained locks within each bucket using thread-safe list

thread-safe single-linked list
- fine-grained locks for each item and hand-over-hand locking for common operations 

## lock-free concurrent data structure

### definition and consequence

blocking and non-blocking
- blocking data structure: use mutex, cv, future with blocking calls
- nonblocking: without blocking call

more specific terms
- Obstruction-Free—If all other threads are paused, then any given thread will complete its operation in a bounded number of steps.
- Lock-Free—If multiple threads are operating on a data structure, then after a bounded number of steps one of them will complete its operation.
- Wait-Free—Every thread operating on a data structure will complete its operation in a bounded number of steps, even if other threads are also operating on the data structure.



## 参考资料

- C++ Concurrency in Action 2nd Edition