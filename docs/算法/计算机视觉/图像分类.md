# 图像分类

## 概述

```{note}
待完善。
```

## 论文

### 20170704 ShuffleNet

#### 1 概述

[ShuffleNet: An Extremely Efficient Convolutional Neural Network for Mobile Devices](https://arxiv.org/abs/1707.01083)指出pointwise convolution具有不可忽视的计算量，论文通过pointwise group convolution及channel shuffle来减少其计算量，构建适用于移动端的轻量网络。

#### 2 主要内容

- pointwise group convoluiton与channel shuffle

深度可分离卷积中pointwise convolution占据主要的计算量，论文通过分组卷积来减少其计算量。

但是，多个group convolution连续堆叠，会造成特征难以在group之间分享，作者通过channel shuffle来解决这一问题。其代码如下：

```python
# 代码来源：https://pytorch.org/vision/stable/_modules/torchvision/models/shufflenetv2.html
def channel_shuffle(x: Tensor, groups: int) -> Tensor:
    batchsize, num_channels, height, width = x.size()
    channels_per_group = num_channels // groups

    # reshape
    x = x.view(batchsize, groups, channels_per_group, height, width)

    x = torch.transpose(x, 1, 2).contiguous()

    # flatten
    x = x.view(batchsize, -1, height, width)

    return x
```

- ShuffleNet Unit

ShuffleNet基本block如下图(b)(c)所示。其中，图(a)是类似于ResNet的bottleneck block，中间采用DWConv；图(b)(c)采用了pointwise group convoluiton与channel shuffle，值得注意的是DWConv后没有激活函数。

假设输入大小为$chw$，bottleneck的通道数未$m$，则图(a)计算量$hw(2cm + 9m)$，图(b)计算量$hw(2cm/g + 9m)$。

![ShuffuleNet Unit](../../images/2017/shufflenet.png)

— scale factor

类似于MobileNet，ShuffleNet提供了宽度乘子来调节模型计算量（调整结果近似于平方）。

#### 3 主要结果

- 保持计算量基本不变，随着pointwise group convolution分组数提高，模型精度基本呈上升趋势；
- with shuffle相比without shuffle，模型精度能够提升2~5百分点；
- 相同计算量下，ShuffleNet优于MobileNet、VGG-like、ResNet、Xception-like、ResNeXt等模型；
- 由于访存等因素，ShuffleNet减少计算量带来的理论加速效果低于实际加速效果。


### 20170417 MobileNet

#### 1 概述

[MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications](https://arxiv.org/abs/1704.04861)基于depthwise separable convolution构建了适用于移动端的轻量网络。

#### 2 主要内容

- depthwise separable convolution

深度可分离卷积如下图所示，其中：$M$为输入通道，$N$为输出通道，$D_K$为卷积核大小。

深度可分离卷积参数量为$MD_KD_K + MN$，传统卷积参数量为：$MND_KD_k$，两者相比为$1/N + 1/(D_KD_K)$。一般而言，$N >> D_KD_K$，所以在深度可分离卷积中参数量主要来源于pointwise convolution。

![Depthwise separable convolution](../../images/2017/depthwise_separable_convolution.png)

- Width Multiplier/Resolution Multiplier

MobileNet通过宽度乘子$\alpha$和分辨率乘子$\rho$来调整模型的计算量（调整效果近似于平方），以适应不同的计算资源。

#### 3 主要结果

- 假设卷积核尺寸为$3\times3$，则深度可分离卷积的计算量近似为传统卷积的$1/9$~$1/8$；
- 保持计算量近似不变，减少网络深度对模型的损害比减少网络宽度更大；
- MobileNet与GoogleNet、VGG16在ImagNet数据集上结果相当，但计算量小得多。


### 20161116 ResNeXt

#### 1 概述

[Aggregated Residual Transformations for Deep Neural Networks](https://arxiv.org/abs/1611.05431v2)采用split-transfrom-aggregate的方式对ResNet进行了改进。

#### 2 主要内容

- Split-Transform-Aggregate

ResNeXt主要改进点如下图(a)所示，对ResNet bottleneck block进行split-transform-aggregate，其与图(b)图(c)等价。本质上，ResNeXt通过分组卷积节省了计算量，在同等计算量下，ResNeXt相比ResNet能够使用更多的通道。

![ResNeXt Block](../../images/2016/resnext.png)

注意：ResNeXt的改进点仅适用于ResNet的bottleneck block，对ResNet两层Layer的blcok并不适用。

#### 3 主要结果

- 在同等计算量下，ResNeXt的结果要优于ResNet；
- 在同等计算量下，随着分组卷积组数的提高，模型的精度呈上升趋势。


### 20151210 ResNet

#### 1 概述

[Deep Residual Learning for Image Recognition](https://arxiv.org/abs/1512.03385)提出残差学习（Residual Learning）来解决深度学习中的degradation问题，即：随着DNN不断加深，模型精度逐渐饱和甚至发生下降。

#### 2 主要内容

- 残差学习（Residual Learning）

假设$H(x)$表示DNN一个block欲拟合的函数，残差学习可以表示为：$F(x) = H(x) - x$。

其核心思想在于，通过添加Identity Mapping（即$x$），使得该block能够在Identity Mapping的基础上进行函数拟合，原先的block仅需拟合残差函数$F(x)$。残差学习使得网络在加深的时候，能够保持已有网络的能力，解决degration问题。

注意，当$F(x)$与$x$的维度不一致时，论文对$x$进行linear projection来进行对齐。对FC来说，添加一个FC即可；对Conv来说，添加一个$1\times1$的卷积。

- 残差block与ResNet

论文采用了两种残差block（如下图所示），两者通道数不同但具有相当的计算量，后者（bottleneck blcok）适用于比较深的DNN以减少计算量。

论文中，前者用在ResNet-{18,34}，后者用在ResNet-{50,101,152}。

![Residual Blcok](../../images/2015/residual_block.png)

#### 3 主要结果

- ResNet随着网络加深，模型精度能够持续提升，未发生degradation问题；
- 在ImageNet2012等公开数据集上，ResNet的结果优于VGG、GoogLeNet、BN-inception等。
