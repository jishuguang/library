# 图像分类

## 概述

```{note}
待完善。
```

## 论文

### 20180113 MobileNetV2

#### 1 概述

[MobileNetV2: Inverted Residuals and Linear Bottlenecks](https://arxiv.org/abs/1801.04381)基于流形学习对CNN进行分析，提出Inverted Residuals及Linear Bottlenecks来改进CNN网络，构建了适用于移动端的MobileNetV2。

#### 2 主要内容

- Manifold of Interest (MOI)

采用ReLU激活函数的CNN有如下特性：1)经ReLU后，若MOI的体积不为空，那么这部分体积对应了一个线性变换；2)经ReLU后MOI蕴含的信息能够得以完整保留的条件是，MOI嵌入在输入空间的一个低维空间中。

通常假设，神经网络的MOI嵌入在一个低维空间中。

- Linear Bottlenecks

论文提出Linear Bottleneck来捕获MOI，同时避免nonlinear对bottleneck layer中蕴含信息的破坏（因为bottleneck layer维度较低，应用nonlinear会导致manifold of interest难以完全保留）。

Linear Bottleneck如下图(c)(d)所示。图(a)是传统卷积（激活函数未标记），长方体代表卷积层输出的未经激活函数的特征图（下同）；图(b)是深度可分离卷积（激活函数未标记）；图(c)深度可分离卷积接Linear Bottleneck Expansion，整个block的输入输出是高维空间特征图；图(d)Linear Bottleneck Expansion接深度可分离卷积，整个block的输入输出是Bottleneck，这是论文采用的基本block。

![Linear Bottleneck](../../images/2018/linear_bottleneck.png)

```{note}
information flow interpretation
```

- Inverted Residual

论文认为bottleneck包含了manifold of interest的主要信息，而“Linear Expansion+深度可分离卷积”只是非线性的一种实现方式，所以将shortcut连接在了bottleneck之上。

整个结构类似于ResNet Bottleneck，但正好相反，所以称为Inverted Residual。

Inverted Residual Block参数量为$hwdt(d + k^2 + d)$，其中$t$为expansion ratio。

```{note}
memory efficient
```

- 模型结构

#### 3 主要结果

#### 4 阅读小记


### 20170905 Squeeze and Excitation

#### 1 概述

[Squeeze and Excitation Networks](https://arxiv.org/abs/1709.01507)提出SE Block用于建模通道之间的关系、调整各通道的输出。

#### 2 主要内容

- SE Block

以SE-ResNet为例（如下图所示），SE Block包括两部分：Squeeze和Excitation。

**Squeeze: Global Information Embedding**：对特征图进行全局平均池化，得到各特征图的全局特征。

**Excitation: Adaptive Recalibration**：用两次FC将全局特征转换为各特征图的调整系数，与特征图相乘。

![SE-ResNet](../../images/2017/se_resnet.png)

```{note}
SE Block可以应用于ResNet Block的不同位置，效果基本一致。

除ResNet之外，SE Block同样可以用于提升ResNeXt、MobileNet、ShuffleNet等。
```

- 复杂度

SE Block的参数量主要来源于两次FC，即$2C^2/r$，其中$r$用于平衡精度与引入的复杂度。对于轻量模型来说，两次FC引入的参数量与pointwise convolution相当，但引入的理论计算量很小。

#### 3 主要结果

- 在ImageNet数据集上，ResNet、ResNeXt、VGG-16、BN-Inception经SE增强后，能提升0.5~1.5个百分点，引入的额外计算量和参数量很小；
- 在ImageNet数据集上，MobileNet、ShuffleNet经SE增强后，能提升1.5~3个百分点，引入的参数量较大，但引入的理论计算量较小；
- SE Block对$r$的取值不敏感，可以选取一个合适的值来平衡精度与引入的复杂度；
- 对于Squeeze来说，全局平均池化略优于全局最大池化；
- SE在不同深度的卷积层中呈现的效果有所不同，在低层中SE表现得class-agnositc，在高层中class-dependent。

#### 4 阅读小记

- SE形式上与作用上类似于Attention机制。
- 虽然SE引入的理论计算量较小，但实际部署中可能会造成一定时延。


### 20170704 ShuffleNet

#### 1 概述

[ShuffleNet: An Extremely Efficient Convolutional Neural Network for Mobile Devices](https://arxiv.org/abs/1707.01083)指出pointwise convolution具有不可忽视的计算量，论文通过pointwise group convolution及channel shuffle来减少其计算量，构建适用于移动端的轻量网络。

#### 2 主要内容

- pointwise group convoluiton与channel shuffle

深度可分离卷积中pointwise convolution占据主要的计算量，论文通过分组卷积来减少其计算量。

但是，多个group convolution连续堆叠，会造成特征难以在group之间分享，论文通过channel shuffle来解决这一问题。其代码如下：

```python
# 代码来源：https://pytorch.org/vision/stable/_modules/torchvision/models/shufflenetv2.html
def channel_shuffle(x: Tensor, groups: int) -> Tensor:
    batchsize, num_channels, height, width = x.size()
    channels_per_group = num_channels // groups

    # reshape
    x = x.view(batchsize, groups, channels_per_group, height, width)

    x = torch.transpose(x, 1, 2).contiguous()

    # flatten
    x = x.view(batchsize, -1, height, width)

    return x
```

- ShuffleNet Block

ShuffleNet基本block如下图(b)(c)所示。其中，图(a)是类似于ResNet的bottleneck block，中间采用DWConv；图(b)(c)采用了pointwise group convoluiton与channel shuffle，值得注意的是DWConv后没有激活函数。

假设输入大小为$chw$，bottleneck的通道数为$m$，则图(a)计算量为$hw(2cm + 9m)$，图(b)计算量为$hw(2cm/g + 9m)$。

![ShuffuleNet Unit](../../images/2017/shufflenet.png)

- scale factor

类似于MobileNet，ShuffleNet提供了宽度乘子来调节模型计算量（调整结果近似于平方）。

#### 3 主要结果

- 保持计算量基本不变，随着pointwise group convolution分组数提高，模型精度基本呈上升趋势；
- with shuffle相比without shuffle，模型精度能够提升2~5百分点；
- 相同计算量下，ShuffleNet优于MobileNet、VGG-like、ResNet、Xception-like、ResNeXt等模型；
- 由于访存等因素，ShuffleNet减少计算量带来的理论加速效果低于实际加速效果。

#### 4 阅读小记

- 通过channel shuffle解决连续分组卷积共享信息的问题，十分巧妙。
- 由于实现、访存等原因，基于理论计算量得到的加速效果并不可靠。


### 20170417 MobileNet

#### 1 概述

[MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications](https://arxiv.org/abs/1704.04861)基于depthwise separable convolution构建了适用于移动端的轻量网络。

#### 2 主要内容

- depthwise separable convolution

深度可分离卷积如下图所示，其中：$M$为输入通道，$N$为输出通道，$D_K$为卷积核大小。

深度可分离卷积参数量为$MD_KD_K + MN$，传统卷积参数量为：$MND_KD_k$，两者相比为$1/N + 1/(D_KD_K)$。一般而言，$N >> D_KD_K$，所以在深度可分离卷积中参数量主要来源于pointwise convolution。

![Depthwise separable convolution](../../images/2017/depthwise_separable_convolution.png)

- Width Multiplier/Resolution Multiplier

MobileNet通过宽度乘子$\alpha$和分辨率乘子$\rho$来调整模型的计算量（调整效果近似于平方），以适应不同的计算资源。

#### 3 主要结果

- 假设卷积核尺寸为$3\times3$，则深度可分离卷积的计算量近似为传统卷积的$1/9$~$1/8$；
- 保持计算量近似不变，减少网络深度对模型的损害比减少网络宽度更大；
- MobileNet与GoogleNet、VGG16在ImagNet数据集上结果相当，但计算量小得多。

#### 4 阅读小记

- 深度可分离卷积能够有效减少传统卷积的计算量，在轻量CNN网络中被广泛使用。
- 第一代MobileNet未采用类似于ResNet的shortcut + Block的结构，模型精度仍有提升的空间。


### 20161116 ResNeXt

#### 1 概述

[Aggregated Residual Transformations for Deep Neural Networks](https://arxiv.org/abs/1611.05431v2)采用split-transfrom-aggregate的方式对ResNet进行了改进。

#### 2 主要内容

- Split-Transform-Aggregate

ResNeXt主要改进点如下图(a)所示，对ResNet bottleneck block进行split-transform-aggregate，其与图(b)图(c)等价。论文在实现时主要采用了图(c)分组卷积。

![ResNeXt Block](../../images/2016/resnext.png)

```{note}
ResNeXt的改进点仅适用于ResNet的bottleneck block，对ResNet两层Layer的blcok并不适用。
```

#### 3 主要结果

- 在同等计算量下，ResNeXt的结果要优于ResNet；
- 在同等计算量下，随着分组卷积组数的提高，模型的精度呈上升趋势。

#### 4 阅读小记

本质上，ResNeXt通过分组卷积节省了计算量，在同等计算量下，ResNeXt相比ResNet能够使用更多的通道，从而提升了模型精度。


### 20151210 ResNet

#### 1 概述

[Deep Residual Learning for Image Recognition](https://arxiv.org/abs/1512.03385)提出残差学习（Residual Learning）来解决深度学习中的degradation问题，即：随着DNN不断加深，模型精度逐渐饱和甚至发生下降。

#### 2 主要内容

- 残差学习（Residual Learning）

假设$H(x)$表示DNN一个block欲拟合的函数，残差学习可以表示为：$F(x) = H(x) - x$。

其核心思想在于，通过添加Identity Mapping（即$x$），使得该block能够在Identity Mapping的基础上进行函数拟合，原先的block仅需拟合残差函数$F(x)$。残差学习使得网络在加深的时候，能够保持已有网络的能力，解决degration问题。

注意，当$F(x)$与$x$的维度不一致时，论文对$x$进行linear projection来进行对齐。对FC来说，添加一个FC即可；对Conv来说，添加一个$1\times1$的卷积。

- 残差block与ResNet

论文采用了两种残差block（如下图所示），两者通道数不同但具有相当的计算量，后者（bottleneck blcok）适用于比较深的DNN以减少计算量。

论文中，前者用在ResNet-{18,34}，后者用在ResNet-{50,101,152}。

![Residual Blcok](../../images/2015/residual_block.png)

#### 3 主要结果

- ResNet随着网络加深，模型精度能够持续提升，未发生degradation问题；
- 在ImageNet2012等公开数据集上，ResNet的结果优于VGG、GoogLeNet、BN-inception等。

#### 4 阅读小记

论文以"残差学习"来解释ResNet的成功。从梯度的角度来看，shortcut使得梯度更容易传播到低层网络，缓解了梯度消失问题。
